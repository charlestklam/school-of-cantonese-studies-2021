{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiword Expressions / Discontinuous Constructions - Charles.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKfHrzcky4ox"
      },
      "source": [
        "# Goals\n",
        "\n",
        "We often need to look up specific characters in corpora to find the examples for the construction of interest. Some constructions are fairly easy to find, because we can look up the specific characters (e.g. aspect 咗, negation 冇). However, some expressions are trickier, as they include multiple elements (which may or may not be contiguous). \n",
        "\n",
        "- 連 … 都\n",
        "- 如果 … 就\n",
        "- 係 唔係\n",
        "\n",
        "\n",
        "Let's load the PyCantonese library first.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmcrAyEkINhE"
      },
      "source": [
        "!pip install pycantonese==3.2.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul517ynLRzBk"
      },
      "source": [
        "Let's find all the examples of 連... 都. \n",
        "\n",
        "If we are looking for examples of 連... 都 with our bare eyes, we would probably be skimming to find 連 first, then check whether there is a 都 nearby.\n",
        "\n",
        "We may also add that 連 should come before 都 to avoid noise in our data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTPDAhx-SRTF"
      },
      "source": [
        "import pycantonese as pc \n",
        "\n",
        "corpus = pc.hkcancor()\n",
        "utterances = corpus.words(by_utterances=True)  # by_utterances=True keeps the utterance boundaries\n",
        "\n",
        "for u in utterances:\n",
        "  if '連' in u and '都' in u and u.index('連') < u.index('都'):\n",
        "    print(u)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW6T-gQwhxag"
      },
      "source": [
        "If we look at the first 2 results, they do not seem to be good examples for the 連...都 construction. We might want to limit the distance between 連 and 都 to avoid false positives.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwbawPzxTL5l"
      },
      "source": [
        "# Update to specify distance \n",
        "\n",
        "import pycantonese as pc \n",
        "\n",
        "corpus = pc.hkcancor()\n",
        "utterances = corpus.words(by_utterances=True)  # by_utterances=True keeps the utterance boundaries\n",
        "\n",
        "window_size = 5 # Here we can specify a window_size to avoid false positives\n",
        "\n",
        "for u in utterances:\n",
        "  if '連' in u and '都' in u and u.index('都')-u.index('連') < window_size:\n",
        "    print(u)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45omvvkcWtn0"
      },
      "source": [
        "# Defining a custom function \n",
        "We are pretty sure we will recyle this idea. \n",
        "\n",
        "We can define a function so we don't have to copy and paste the whole thing over and over again. There are 3 things we need to specify each time: \n",
        "\n",
        "  1. The beginning word, which should be a character\n",
        "  2. The end word, also a character\n",
        "  3. The window size, which should be an integer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOl7wHVDbIIU"
      },
      "source": [
        "def find_mwe(text,begin_word,end_word,window_size): #This function finds Multiword Expressions, with 4 arguments: the text to look up, beginning word, end word, and the search window size. \n",
        "  for u in text:\n",
        "    if begin_word in u and end_word in u and u.index(end_word)-u.index(begin_word) < window_size:\n",
        "      print(u)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PzxrJXCb7hF"
      },
      "source": [
        "# We have used the name 'utterances' for our text \n",
        "# Beginning word: '連'\n",
        "# End word: '都' \n",
        "# Window size: 5 \n",
        "\n",
        "find_mwe(utterances,'連','都',5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBy0efclJBlG"
      },
      "source": [
        "## Exercise 1\n",
        "\n",
        "Let's try the same thing with some other constructions. Here are some candidates, but feel free to come up with your own search queries! Not that the appropriate window size depends largely on the construction. \n",
        " \n",
        "1. 如果 ... 就 \n",
        "2. 咪 ... 囖\n",
        "\n",
        "3. 係唔係 \n",
        "  - We may want to make sure '係' and '唔係' are next to each other. We can specify the index to ensure that. In the current segmentation, '係' is one word and '唔係' is another. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj8bvwhQUWE6"
      },
      "source": [
        "# Use '如果' and '就' for the keywords, set the window size to 10  \n",
        "# Don't forget to put '如果' and '就' in quotes!  \n",
        "\n",
        "find_mwe(utterances, , , )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCc8HgJ7j_Et"
      },
      "source": [
        "# Use '咪' and '囖' for the keywords, set the window size to 5 \n",
        "# Don't forget to put '咪' and '囖' in quotes!  \n",
        "\n",
        "find_mwe(utterances, , , )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY4n_7fXgXrJ"
      },
      "source": [
        "## Exercise 2\n",
        "\n",
        "In addition, there are over 300 tokens of '係 唔係', it might be useful to store the results in a list. \n",
        "\n",
        "We can update the `find_mwe` function as `find_mwe_as_list`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb50gYV8Qi-I"
      },
      "source": [
        "def find_mwe_as_list(text,begin_word,end_word,window_size): #This function finds Multiword Expressions, with 3 arguments: beginning word, end word, and the search window size. \n",
        "  results = []\n",
        "  for u in text:\n",
        "    if begin_word in u and end_word in u and u.index(end_word)-u.index(begin_word) < window_size:\n",
        "      results.append(u)\n",
        "  return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfvWeI4ZlBUY"
      },
      "source": [
        "# Modify the line below to get '係' '唔係', which are contigous! \n",
        "hai6m4hai6 = find_mwe_as_list(utterances, , , )\n",
        "\n",
        "len(hai6m4hai6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNKmAI-tOlht"
      },
      "source": [
        "# Variable Keywords\n",
        "\n",
        "Some constructions involve repetition of lexical items, rather than specific characters. \n",
        "\n",
        "For example, reduplications like 睇一睇 cannot be found directly through keyword search. \n",
        "\n",
        "Note that there are cases like '起 一 起壇' or '褪 一 褪後', where the element before and after 一 are not identical. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlaiuOSPtyu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d64f01-0944-4040-803b-8709f90d100e"
      },
      "source": [
        "!pip install --upgrade nskipgrams # To work with ngrams (i.e. strings of multiple words), we can use the `nskipgrams` package"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: nskipgrams in /usr/local/lib/python3.7/dist-packages (0.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz-aZt4jtv8_",
        "outputId": "9ab8cf3f-ec2e-46cc-986f-73d68ec54282"
      },
      "source": [
        "import nskipgrams\n",
        "\n",
        "utterances = corpus.words(by_utterances=True)\n",
        "\n",
        "results = []\n",
        "\n",
        "for u in utterances:\n",
        "  for trigram in nskipgrams.ngrams_from_seq(u, n=3):\n",
        "    if \"一\" == trigram[1] and trigram[0] in trigram[2]:\n",
        "      results.append(trigram)\n",
        "\n",
        "len(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph2bVir_kiNl"
      },
      "source": [
        "#Let's look at some results \n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kz51ZRHxcst"
      },
      "source": [
        "NB: There are false positives!\n",
        "\n",
        "- 佢 啲 signal 係 **一 Group 一 Group** 𡃉 . (from HKCanCor ``FC-025_v.txt``, line 277)\n",
        "- 講真 揾 唔 到 工 哩 啲 嘢 , 都 係 即係 **- 一 - ** 係 - 點 講 啊 ? (from HKCanCor ``FC-105_v2.txt``, line 370)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ8QUQQ1YXTd"
      },
      "source": [
        "## Exercise 3\n",
        "\n",
        "Using the same approach, we can identify more complex strings like 'V 來 V 去'. Modify the codes below to find 'V 來 V 去'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOyQomffysJm"
      },
      "source": [
        "results = []\n",
        "\n",
        "for u in utterances:\n",
        "  # The 'V 來 V 去' combination should form a 4-gram, not 3. We can name it 'fourgram' instead of 'trigram'.  \n",
        "  for trigram in nskipgrams.ngrams_from_seq(u, n=3):\n",
        "    # We want to specify that (1) the index of 來 is the second element, (2) the index of 去 is the 4th element, \n",
        "    # and (3) the first and the third elements are identical\n",
        "    if \"一\" == trigram[1] and trigram[0] in trigram[2]:\n",
        "      results.append(trigram)\n",
        "\n",
        "len(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylOUjAaZ0WGo"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65To8oFXuiW6"
      },
      "source": [
        "## Exercise 4\n",
        "\n",
        "- Feel free to play with another constructions involving reduplicative elements. \n",
        "\n",
        "- Since different contructions might be subject to very different restrictions, defining a dedicated function might not be as efficient. \n",
        "\n",
        "  1. AA哋 (e.g. 肥肥哋)\n",
        "  2. V下V下 (e.g. 爬下爬下)\n",
        "  3. A-not-A (e.g. 會唔會, 可唔可以)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDD5Wmfp3hJU"
      },
      "source": [
        "# 哋\n",
        "results = []\n",
        "\n",
        "for u in utterances:\n",
        "  for fourgram in nskipgrams.ngrams_from_seq(u, n=3): #Try changing n to 4 here! \n",
        "    #Modify the following line\n",
        "    if \"\" == fourgram[2] and fourgram[0] in fourgram[1]:\n",
        "      results.append(fourgram)\n",
        "\n",
        "print(len(results))\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z06ibZe6EGi2"
      },
      "source": [
        "# V 下 V 下"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur2zwh-gEIRY"
      },
      "source": [
        "# A 唔 A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaFlwlWJdNnx"
      },
      "source": [
        "# Epilogue\n",
        "\n",
        "- From these constructions, we can see that the knowledge about the constructions is vital in the coding (e.g. '褪一褪後' is possible but *'褪後一褪' isn't). \n",
        "\n",
        "- In other cases, we want to specify whether two elements are identical or one element is found within another one (e.g. 會唔會, 可唔可以, *可唔可). \n",
        "\n",
        "- Widening the window is often helpful in exploration. "
      ]
    }
  ]
}
